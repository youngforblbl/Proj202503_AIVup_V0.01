import os
import re
import json
import requests
from Chat_api_test import communicate_with_llm  # å¯¼å…¥èŠå¤©å‡½æ•°
from ChatMEM_api_test import export_and_upload_chat_history  # å¯¼å…¥èŠå¤©å†å²ä¸Šä¼ å‡½æ•°

# é…ç½® API ç›¸å…³å‚æ•°
API_KEY = "è¾“å…¥ä½ çš„APIå¯†é’¥"
WORKSPACE_SLUG = "dsexv2_v0-dot-0-dot-2" # å¾ˆé€†å¤©çš„å·¥ä½œåŒºSLUGï¼Œå»ºè®®åœ¨anything_LLMçš„apiæ–‡æ¡£ä¸­æŸ¥è¯¢å·¥ä½œåŒºslugæˆ–åœ¨å‘½åå·¥ä½œåŒºæ—¶åªç”¨å°å†™å­—æ¯å’Œæ•°å­—ï¼ˆç¬¦å·ä¹Ÿåˆ«ç”¨ï¼‰

# è®¡æ•°å™¨ & è®°å½•ä¸Šä¸€è½®çš„ `latest_doc_hash`
chat_count = 0
latest_doc_hash = None  # ç”¨äºå­˜å‚¨æœ€æ–°çš„æ–‡æ¡£ Hash
TEMP_FILE = "chat_history.json"  # å­˜å‚¨èŠå¤©è®°å½•çš„ JSON æ–‡ä»¶

def main():
    global chat_count, latest_doc_hash

    print("æ¬¢è¿ä½¿ç”¨ LLM Chat äº¤äº’ç³»ç»Ÿï¼è¾“å…¥ 'exit' é€€å‡ºå¯¹è¯ã€‚")

    while True:
        # ç”¨æˆ·è¾“å…¥
        user_input = input("\nä½ : ")
        if user_input.lower() == "exit":
            print("é€€å‡ºèŠå¤©ã€‚")
            break

        # å‘é€æ¶ˆæ¯åˆ° LLM
        try:
            response = communicate_with_llm(user_input, API_KEY, WORKSPACE_SLUG)
            print(f"AI: {response}")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")
            continue

        # è®¡æ•°èŠå¤©æ¬¡æ•°
        chat_count += 1

        # æ¯ 10 æ¬¡èŠå¤©ä¸Šä¼ ä¸€æ¬¡å†å²è®°å½•
        if chat_count % 10 == 0:
            print("\nğŸ“ 1 æ¬¡å¯¹è¯å·²å®Œæˆï¼Œæ­£åœ¨ä¸Šä¼ èŠå¤©è®°å½•...")
            try:
                upload_status, new_doc_hash = export_and_upload_chat_history(API_KEY, WORKSPACE_SLUG, TEMP_FILE, latest_doc_hash)
                print(f"âœ… {upload_status}")

                # **æ›´æ–°æœ€æ–°çš„ Hash**
                latest_doc_hash = new_doc_hash

            except Exception as e:
                print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")


# è¯¥mainæµ‹è¯•ä¸anythingLLMçš„è¿æ¥ï¼Œå¯åŠ¨åå¯ä½œä¸ºèŠå¤©ç¨‹åº
if __name__ == "__main__":
    main()
